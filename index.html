<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>onnx2versal: onnx2versal</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">onnx2versal
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">onnx2versal </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_README"></a> Presentation Slides: <a href="https://docs.google.com/presentation/d/1xq7Fp-YRgMAOc_wpQ1FjY7M9irCAVrBn46ohUy1YuEw/edit?usp=sharing">https://docs.google.com/presentation/d/1xq7Fp-YRgMAOc_wpQ1FjY7M9irCAVrBn46ohUy1YuEw/edit?usp=sharing</a> <br  />
 This covers an introduction to AI Engines, its architecture, onnx2versal and benchmark results on Tiny MLPerf.</p>
<h1><a class="anchor" id="autotoc_md1"></a>
What are AI engines?</h1>
<p>The AI engine is a part of Versal Adaptive Compute Acceleration Platform (ACAP) architecture, designed for high compute density, deterministic timing and high performance applications. It comprises of an <b>array of tiles that support Very Long Instruction Word (VLIW) parallelism, and SIMD fixed point and floating point processors</b>. Below are images taken from Xilinx docs showing tile components and interfaces.</p>
<div align="center"> <img src="docs/images/aiecomponents.png" alt="" height="250" class="inline"/> <img src="docs/images/aieinterfaces.png" alt="" height="250" class="inline"/> </div><p> <br  />
</p>
<p>For more details</p><ul>
<li>Architecture documentation: <a href="https://docs.xilinx.com/r/en-US/am009-versal-ai-engine/Overview">https://docs.xilinx.com/r/en-US/am009-versal-ai-engine/Overview</a></li>
<li>Main website: <a href="https://www.xilinx.com/products/technology/ai-engine.html">https://www.xilinx.com/products/technology/ai-engine.html</a></li>
<li>White paper: <a href="https://www.xilinx.com/content/dam/xilinx/support/documents/white_papers/wp506-ai-engine.pdf">https://www.xilinx.com/content/dam/xilinx/support/documents/white_papers/wp506-ai-engine.pdf</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md2"></a>
What is onnx2versal?</h1>
<p>This repo holds AIE kernels/graphs and generator scripts to create system level design for AI engines given <code>some_model.onnx</code> and <code>some_data.npy</code>. It is built on top of AI Engine ISA, AIE programming API and the ADF graph programming model. Verify, profile and run your ONNX models on AI engine machines!</p>
<div align="center"> <img src="docs/images/onnx2versal.png" alt="" width="600" class="inline"/> </div><h2><a class="anchor" id="autotoc_md3"></a>
TLDR CLI commands</h2>
<div class="fragment"><div class="line">GRAPH=tiny_kws</div>
<div class="line"> </div>
<div class="line"># Step 1: fuse</div>
<div class="line">python fuse_onnx.py ../models/${GRAPH}.onnx ../models/${GRAPH}.onnx</div>
<div class="line"> </div>
<div class="line"># Step 2: quantize</div>
<div class="line">python -m onnxruntime.quantization.preprocess --input ../models/${GRAPH}.onnx --output ../models/${GRAPH}_infer.onnx</div>
<div class="line">python quantize_onnx.py ../models/${GRAPH}_infer.onnx ../models/${GRAPH}_int8.onnx ../data/$GRAPH/X_test.npy</div>
<div class="line"> </div>
<div class="line"># Step 3: generate</div>
<div class="line">python generate.py ../models/${GRAPH}_int8.onnx ../data/$GRAPH/X_test.npy</div>
<div class="line"> </div>
<div class="line"># Step 4: Test latency</div>
<div class="line">TARGET=hw_emu GRAPH=${GRAPH}_int8 make graph aiesim_profile</div>
<div class="line"> </div>
<div class="line"># Step 5: Test throughput</div>
<div class="line">TARGET=hw_emu DOUT=0 DLOG=0 GRAPH=${GRAPH} make graph clean_reports aiesim ITER_CNT=2</div>
<div class="line">python throughput.py reports_dir/$GRAPH/hw_emu/aiesimulator_output/k*</div>
<div class="line"> </div>
<div class="line"># Step 6: Build for hardware</div>
<div class="line">TARGET=hw DOUT=0 DLOG=0 GRAPH=${GRAPH} make graph kernels xsa application package</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md4"></a>
@ref "/github/workspace/docs/md/usage.md" "Usage"</h1>
<ul>
<li>See setup and how to run details at docs/md/usage.md</li>
<li>See end to end example at Lenet Example. <em>TODO: this example has not been updated and tested for a while.</em></li>
<li>See jupyter notebooks that run through the same examples at<ul>
<li>Conversion to Onnx <a href="python/part1_pytorch2onnx.ipynb">pytorch2onnx notebook</a>, <a href="python/part1_tf2onnx.ipynb">tf2onnx notebook</a></li>
<li>Onnx2Versal <a href="python/part2_onnx2versal.ipynb">onnx2versal notebook</a> <br  />
</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md5"></a>
@ref "/github/workspace/docs/md/profile.md" "How good are the AI engines?"</h1>
<ul>
<li>See details at docs/md/profile.md</li>
</ul>
<p>The pipeline has been tested for Tiny MLPerf models. The models below are trained from hls4ml-finn repositories for direct comparison with hls4ml implementation. It has shown latency improvements of 5x (Keyword Spotting), 8x (Image Classifciation) and 18x (Anomaly Detection) under 11-15% utilization. For details on the hls4ml implementation see <a href="https://cds.cern.ch/record/2826586/files/2206.11791.pdf">Hls4ml MLPerf Tiny paper</a>.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Use Case   </th><th class="markdownTableHeadCenter">Dtype   </th><th class="markdownTableHeadCenter">Latency (cycles or ns)   </th><th class="markdownTableHeadCenter">Throughput (samples/s)   </th><th class="markdownTableHeadCenter">Resource Utilization (Kernels/Buffers/Stream/PLIO/GMIO)   </th><th class="markdownTableHeadCenter">Accuracy (first 1k)   </th><th class="markdownTableHeadCenter">Quality Target   </th><th class="markdownTableHeadCenter">Model    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Keyword Spotting   </td><td class="markdownTableBodyCenter">fp32 <br  />
 uint8   </td><td class="markdownTableBodyCenter">35076 <br  />
 3159   </td><td class="markdownTableBodyCenter">75369 <br  />
 1157407   </td><td class="markdownTableBodyCenter">46/56/116/5/24 <br  />
 48/51/83/7/0   </td><td class="markdownTableBodyCenter">84.8% (Top 1)   </td><td class="markdownTableBodyCenter">82.5% (Top 1)   </td><td class="markdownTableBodyCenter"><a href="https://github.com/hls4ml-finn-mlperftiny/tiny_results_v0.7/blob/main/open/hls4ml-finn/code/kws/KWS-W3A3/training/model/models.py">MLP</a>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Anomaly Detection   </td><td class="markdownTableBodyCenter">fp32 <br  />
 uint8   </td><td class="markdownTableBodyCenter">3165 <br  />
 1014   </td><td class="markdownTableBodyCenter">3205128 <br  />
 7142857   </td><td class="markdownTableBodyCenter">44/58/128/7/0 <br  />
 46/48/76/2/0   </td><td class="markdownTableBodyCenter">0.830 (AUC)   </td><td class="markdownTableBodyCenter">0.83 (AUC)   </td><td class="markdownTableBodyCenter"><a href="https://github.com/hls4ml-finn-mlperftiny/tiny_results_v0.7/blob/main/open/hls4ml-finn/code/ad/AD08/training/keras_model.py">AutoEncoder</a>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Image Classification   </td><td class="markdownTableBodyCenter">fp32 <br  />
 uint8   </td><td class="markdownTableBodyCenter">739274 <br  />
 174992   </td><td class="markdownTableBodyCenter">4324 <br  />
 22258   </td><td class="markdownTableBodyCenter">62/68/125/9/7 <br  />
 90/95/144/2/5   </td><td class="markdownTableBodyCenter">84.1% (Top 1)   </td><td class="markdownTableBodyCenter">83.5% (Top 1)   </td><td class="markdownTableBodyCenter"><a href="https://github.com/hls4ml-finn-mlperftiny/tiny_results_v0.7/blob/main/open/hls4ml-finn/code/ic/RN07/training/resnet_v1_eembc.py">CNN</a>   </td></tr>
</table>
<ul>
<li>Latency is calculated based on cycle count from cycle-accurate aiesimulator through AI Engine programming logging API, specifically <code>aie::tile::current().cycles()</code>. Obtained through aiesimulator logs.</li>
<li>Throughput is calculated based on output bandwidth over multiple iterations. Obtained by running <code>throughput.py</code> on aiesimulator output files and assumes AI engine is clocked at 1GHz.</li>
</ul>
<h1><a class="anchor" id="autotoc_md6"></a>
Issues</h1>
<p>Below are certain issues that may arise from using the pipeline. </p>
<h2><a class="anchor" id="autotoc_md7"></a>
Certain operations, input shapes or parameter sizes is not supported</h2>
<ol type="1">
<li>Write a op. Files required:<ul>
<li><code>design/aie_src/my_op.cc</code></li>
<li><code>design/aie_src/my_op.h</code></li>
<li><code>design/aie_src/graph_my_op.cpp</code></li>
<li><code>design/aie_src/graph_my_op.h</code></li>
</ul>
</li>
<li>Add data. Files required:<ul>
<li><code>data/my_op_in.txt</code></li>
<li><code>data/my_op_golden.txt</code></li>
</ul>
</li>
<li>Test it:<ul>
<li>x86 Graph test: <code>TARGET=sw_emu GRAPH=my_op make clean_reports graph aiesim # X86 GRAPH</code></li>
<li>SysC Graph test: <code>TARGET=hw_emu GRAPH=my_op make clean_reports graph aiesim # SYSC GRAPH</code></li>
</ul>
</li>
</ol>
<h2><a class="anchor" id="autotoc_md8"></a>
There are issues generating the ADF graph</h2>
<ol type="1">
<li>See reference generated graph from example</li>
<li>See documentation for any dimension restrictions for kernels/graphs.</li>
<li>Write the high level ADF graph for the network</li>
</ol>
<h2><a class="anchor" id="autotoc_md9"></a>
Important documentation</h2>
<ul>
<li><a href="https://rehohoho.github.io/onnx2versal/">AIE kernels and graphs used in this repo</a></li>
<li><a href="https://github.com/Xilinx/Vitis-Tutorials/tree/2022.1/AI_Engine_Development">Vitis Tutorials - AI Engine Development</a></li>
<li><a href="https://docs.xilinx.com/r/en-US/ug1079-ai-engine-kernel-coding/">AI Engine Kernel and Graph Programming Guide (UG1079)</a></li>
<li><a href="https://www.xilinx.com/htmldocs/aiengine_intrinsics_start.html">AI Engine Documentation - AIE API or Intrinsic guide</a></li>
<li><a href="https://docs.xilinx.com/r/en-US/ug1076-ai-engine-environment/">AI Engine Tools and Flows User Guide (UG1076)</a></li>
<li><a href="https://docs.xilinx.com/r/en-US/ug1399-vitis-hls">Vitis HLS</a></li>
<li><a href="https://xilinx.github.io/XRT/master/html/index.html">XRT Documentation - Host application programming docs</a></li>
<li><a href="https://github.com/Xilinx/XRT/blob/master/src/runtime_src/core/include/experimental/xrt_aie.h">XRT AIE API - xrt_aie.h</a> </li>
</ul>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
